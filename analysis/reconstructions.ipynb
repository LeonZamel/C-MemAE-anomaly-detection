{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook can be used to test a model on training/testing data to see how well reconstruction works. It is also possible to visualize memory entries directly"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys; sys.path.insert(0, '..')\n",
    "import torch \n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from collections.abc import Iterable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from systems.memae_autoencoder_system import MemaeSystem\n",
    "from systems.ae_autoencoder_system import AESystem\n",
    "from models.conditional.conditional_memae_mnist import ConditionalMemaeMNIST\n",
    "from models.memae_mnist_flat import MemaeMNISTFlat\n",
    "from datamodules.mnist_dm import MNISTDataModule\n",
    "from datamodules.cifar_dm import CIFARDataModule\n",
    "\n",
    "from helpers import parse_runs, select_checkpoint_from_run_df, show_normalized_img, plot_vector_as_bar\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Specify the directories of the data that should be loaded.\n",
    "# All subfolders are automatically analyzed\n",
    "data_dirs = [\n",
    "\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the data and select the checkpoint\n",
    "runs = parse_runs(data_dirs, [\"Seed\", \"Model Type\"]) # Always create a seed level\n",
    "checkpoint = select_checkpoint_from_run_df(runs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the checkpoint\n",
    "print(f\"Selected: '{checkpoint.value}'\")\n",
    "system = AESystem.load_from_checkpoint(checkpoint.value, learning_rate=0)\n",
    "_ = system.eval()"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualize the memory entries\n",
    "memory = system.model.mem_rep.memory\n",
    "if not isinstance(memory, Iterable):\n",
    "    # Memory is not conditional, put it in a list so we can still iterate it\n",
    "    memory = [memory]\n",
    "\n",
    "for mem in memory:\n",
    "    for i in range(10):\n",
    "        entry = mem.weight[i]\n",
    "        decoded_mem = system.model.decoder(entry.unsqueeze(0).unsqueeze(2).unsqueeze(2))\n",
    "        show_normalized_img(decoded_mem, save=False, None)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load a sample from the dataset\n",
    "data_sample_class = 0\n",
    "condition = None\n",
    "dm = CIFARDataModule([data_sample_class], 1, 1, data_dir='../data')\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "# Perform reconstruction\n",
    "samples,y = next(iter(dm.train_dataloader()))\n",
    "\n",
    "if condition is not None:\n",
    "    out = system(sample, torch.tensor([condition]))\n",
    "else:\n",
    "    out = system(sample)\n",
    "\n",
    "show_normalized_img(sample, save=False, filename=None)\n",
    "show_normalized_img(out, save=False, filename=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualize the various stages of the addressing vector\n",
    "encoded = system.model.encoder(sample).detach()\n",
    "out = system.model.mem_rep(encoded)\n",
    "encoded_hat = out[\"output\"].detach()\n",
    "att = out[\"att\"].detach()\n",
    "att_pre_softmax = out[\"pre_softmax_att\"].detach()\n",
    "att_post_softmax = F.softmax(att_pre_softmax, dim=1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_vector_as_bar(encoded.flatten(), \"Value\", \"Index\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_vector_as_bar(att_pre_softmax.flatten(), \"Value\", \"Index\", False, \"attention_pre_softmax\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_vector_as_bar(att_post_softmax.flatten(), \"Value\", \"Index\", False, \"attention_post_softmax\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_vector_as_bar(att.flatten(), \"Value\", \"Index\", False, \"attention_final\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_vector_as_bar(encoded_hat.flatten(), \"Value\", \"Index\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}